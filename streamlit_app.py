import streamlit as st
import pandas as pd
import pdfplumber
from anthropic import Anthropic
import tempfile, base64

# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ APIã‚­ãƒ¼å…¥åŠ› =====
st.sidebar.header("ğŸ”‘ APIè¨­å®š")
api_key = st.sidebar.text_input("Anthropic API Key", type="password")
if api_key:
    st.session_state["api_key"] = api_key

# ===== Claudeå‘¼ã³å‡ºã—é–¢æ•° =====
def analyze_pdf_with_summary(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            t = page.extract_text()
            if t:
                text += t + "\n"
    if not text.strip():
        return "ä¸æ˜", "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§ããš"

    client = Anthropic(api_key=st.session_state["api_key"])
    prompt = f"""
ä»¥ä¸‹ã¯è¨­å‚™ç‚¹æ¤œå ±å‘Šæ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚

1. æŒ‡æ‘˜äº‹é …ãŒã‚ã‚‹å ´åˆã¯ã€ŒæŒ‡æ‘˜ã‚ã‚Šã€ï¼å•é¡ŒãŒãªã‘ã‚Œã°ã€ŒæŒ‡æ‘˜ãªã—ã€
2. æŒ‡æ‘˜ãŒã‚ã‚‹å ´åˆã¯ãã®å†…å®¹ã‚’2ã€œ3è¡Œã§è¦ç´„

æ¬¡ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
æœ‰ç„¡: â—‹â—‹
æ¦‚è¦: â—‹â—‹
---
{text[:6000]}
"""
    resp = client.messages.create(
        model="claude-3-opus-20240229",
        max_tokens=500,
        messages=[{"role": "user", "content": prompt}]
    )
    output = resp.content[0].text.strip()

    has_issue, summary = "ä¸æ˜", ""
    for line in output.splitlines():
        if line.startswith("æœ‰ç„¡:"):
            has_issue = line.replace("æœ‰ç„¡:", "").strip()
        if line.startswith("æ¦‚è¦:"):
            summary = line.replace("æ¦‚è¦:", "").strip()
    return has_issue, summary

# ===== PDFãƒªãƒ³ã‚¯ç”Ÿæˆé–¢æ•° =====
def make_download_link(uploaded_file):
    data = uploaded_file.read()
    b64 = base64.b64encode(data).decode()
    href = f'<a href="data:application/pdf;base64,{b64}" download="{uploaded_file.name}">ğŸ“¥ {uploaded_file.name}</a>'
    return href

# ===== ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =====
st.title("ğŸ“Š ã‚°ãƒªãƒ¼ãƒ³ã‚ªãƒ¼ã‚¯èŒ…å ´ç”º æœˆæ¬¡å ±å‘Šæ›¸")

uploaded_csv = st.file_uploader("ğŸ“‚ ç‚¹æ¤œãƒã‚±ãƒƒãƒˆCSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")
uploaded_pdfs = st.file_uploader("ğŸ“‚ PDFå ±å‘Šæ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰", type="pdf", accept_multiple_files=True)

if uploaded_csv is not None:
    tickets = pd.read_csv(uploaded_csv)

    pdf_results = {}
    if uploaded_pdfs:
        for pdf in uploaded_pdfs:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦è§£æ
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(pdf.getvalue())
                pdf_path = tmp.name
            has_issue, summary = analyze_pdf_with_summary(pdf_path)

            # ãƒªãƒ³ã‚¯ç”Ÿæˆ
            link = make_download_link(pdf)

            pdf_results[pdf.name] = {"æœ‰ç„¡": has_issue, "æ¦‚è¦": summary, "ãƒªãƒ³ã‚¯": link}

    # CSVã«ã€ŒæŒ‡æ‘˜æœ‰ç„¡ã€ã€ŒæŒ‡æ‘˜å†…å®¹ã€ã€Œãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€åˆ—ã‚’è¿½åŠ 
    tickets["æŒ‡æ‘˜æœ‰ç„¡"] = tickets["å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«"].map(lambda x: pdf_results.get(x, {}).get("æœ‰ç„¡", "ä¸æ˜"))
    tickets["æŒ‡æ‘˜å†…å®¹"] = tickets["å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«"].map(lambda x: pdf_results.get(x, {}).get("æ¦‚è¦", ""))
    tickets["ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"] = tickets["å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«"].map(lambda x: pdf_results.get(x, {}).get("ãƒªãƒ³ã‚¯", ""))

    # ===== ã‚µãƒãƒªãƒ¼ =====
    st.metric("ç·ä½œæ¥­ä»¶æ•°", len(tickets))
    st.metric("æŒ‡æ‘˜äº‹é …ã‚ã‚Š", (tickets["æŒ‡æ‘˜æœ‰ç„¡"] == "æŒ‡æ‘˜ã‚ã‚Š").sum())
    st.metric("æŒ‡æ‘˜äº‹é …ãªã—", (tickets["æŒ‡æ‘˜æœ‰ç„¡"] == "æŒ‡æ‘˜ãªã—").sum())
    st.metric("æ‹…å½“æ¥­è€…æ•°", tickets["æ‹…å½“ä¼šç¤¾"].nunique())

    # ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒªãƒ³ã‚¯ã‚’æœ‰åŠ¹åŒ–ï¼‰
    st.write("### ç‚¹æ¤œãƒã‚±ãƒƒãƒˆä¸€è¦§")
    st.write(tickets.to_html(escape=False, index=False), unsafe_allow_html=True)

    # ===== HTMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ =====
    html_content = tickets.to_html(escape=False, index=False)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as f:
        f.write(html_content.encode("utf-8"))
        tmpfile = f.name
    with open(tmpfile, "rb") as f:
        st.download_button("ğŸ“¥ HTMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name="monthly_report.html")
